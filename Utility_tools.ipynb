{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b53bcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_pearson_corr():\n",
    "\n",
    "    def __init__(self, data, column1: str, column2: str): \n",
    "        self.data = data\n",
    "        self.column1 = column1\n",
    "        self.column2 = column2\n",
    "        self.data_exp = self.data.copy()\n",
    "        self.cols = [self.column1, self.column2]\n",
    "        assert(self.column1 in self.data.columns and self.column2 in self.data.columns)\n",
    "        assert(self.data[self.column1].dtype!='O' and self.data[self.column2].dtype!='O')\n",
    "\n",
    "    def normality_visual(self):\n",
    "        print('Checking for Gaussian distribution:\\n')\n",
    "        for column in self.cols:\n",
    "            fig = qqplot(self.data[column], line = '45', fit=True)\n",
    "            ax = plt.gca() \n",
    "            fig.set_size_inches(15, 8) \n",
    "            ax.set_xlabel('Theoretical Quantiles', fontsize=13)\n",
    "            ax.set_ylabel(f'Sample Quantiles of the {column} column', fontsize=13)\n",
    "            plt.show()\n",
    "      \n",
    "    def normality_test(self):\n",
    "        print('Shapiro-Wilk test for normality:\\n')\n",
    "        for column in self.cols:\n",
    "            print(f'''P-value for {column} column: {shapiro(self.data[column])[1]}\\n''')\n",
    "            \n",
    "    def outlier_sensitivity(self):\n",
    "        print('Checking outlier sensitivity:\\n')\n",
    "        for column in self.cols:\n",
    "            find_outlier_records(self.data, column_name=column)\n",
    "            \n",
    "    def linearity_corr(self):\n",
    "        print('Checking for Linearity:\\n')\n",
    "        sns.regplot(x = self.column1, y = self.column2, data=self.data, color='b') \n",
    "        plt.show() \n",
    "        \n",
    "    def pearson_corr_coef(self):\n",
    "        print(f'Pearson correlation coefficient without outlier handling: {self.data[self.column1].corr(self.data[self.column2])}')\n",
    "        for column in self.cols:\n",
    "            coerce_outliers_zscore(self.data_exp, column_name=column) \n",
    "        print(f'Pearson correlation coefficient with outlier handling: {self.data_exp[self.column1].corr(self.data_exp[self.column2])}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a08cfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_anova_corr():\n",
    "    \n",
    "    def __init__(self, data, cat_col: str, con_col: str):\n",
    "        self.data = data\n",
    "        self.cat_col = cat_col\n",
    "        self.con_col = con_col\n",
    "        assert(self.cat_col in self.data.columns and self.con_col in self.data.columns)\n",
    "        assert(self.data[self.cat_col].dtype=='O' and self.data[self.con_col].dtype!='O')\n",
    "\n",
    "    def check_mean_cat(self):\n",
    "        mean_cat = self.data.groupby(self.cat_col)[self.con_col].agg(['count', 'mean'])\n",
    "        return mean_cat\n",
    "    \n",
    "    def compare_mean_visual(self):\n",
    "        plt.figure(figsize=(15,8))\n",
    "        sns.set_palette(\"Reds\", 4)\n",
    "        sns.boxplot(x=self.cat_col, y=self.con_col, data=self.data)\n",
    "        sns.stripplot(x=self.cat_col, y=self.con_col, data=self.data, jitter=0.4, color=\"0.3\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.show()\n",
    "    \n",
    "    def check_gaussian_visual(self):\n",
    "        for cat in self.data[self.cat_col].unique():\n",
    "            fig = qqplot(self.data[self.data[self.cat_col]==cat][self.con_col], line = '45', fit=True)\n",
    "            ax = plt.gca()\n",
    "            fig.set_size_inches(15, 8)\n",
    "            ax.set_xlabel('Theoretical Quantiles', fontsize=13)\n",
    "            ax.set_ylabel(f'Sample Quantiles of the {cat} category', fontsize=13)\n",
    "            ax.set_title(\"QQ Plot of Categories\", fontsize=16)\n",
    "            plt.show()\n",
    "     \n",
    "    def check_gaussian_stat(self):\n",
    "        for cat in self.data[self.cat_col].unique():\n",
    "            print(f'''P-value for {cat} category: {shapiro(self.data[self.data[self.cat_col]==cat][self.con_col])}''')    \n",
    "        \n",
    "    def check_residual_sum_normality(self):\n",
    "        st = ols(\"self.con_col ~ C(self.cat_col)\", data = self.data).fit()\n",
    "        residuals = st.resid\n",
    "        fig = qqplot(residuals, line = '45', fit=True)\n",
    "        ax = plt.gca()\n",
    "        fig.set_size_inches(15, 8)\n",
    "        ax.set_xlabel(\"Theoretical Quantiles\", fontsize=13)\n",
    "        ax.set_ylabel(\"Sample Quantiles\", fontsize=13)\n",
    "        ax.set_title(\"QQPlot of the Residuals\", fontsize=16)\n",
    "        plt.show()   \n",
    "    \n",
    "    def check_equal_variances(self):\n",
    "        self.data.groupby(self.cat_col)[self.cat_col].describe()['std'].to_frame() \n",
    "        self.homoscedasticity_test = levene(data[data[cat_col]=='Orthodox']['SLpM'], df[df['stance']=='Southpaw']['SLpM'],\n",
    "                              df[df['stance']=='Switch']['SLpM'])\n",
    "        print(f'''Levene's test p-value: {self.homoscedasticity_test[1]}''')\n",
    "        \n",
    "    def anova_test(self):\n",
    "        lm = ols('self.con_col ~ C(self.cat_col)', data=self.data).fit()\n",
    "        table = anova_lm(lm)\n",
    "        mc = pairwise_tukeyhsd(self.data[self.con_col], self.data[self.cat_col])\n",
    "        result = mc._results_table\n",
    "        return (table, result, mc.groupsunique)\n",
    "    \n",
    "    def welch_test(self):\n",
    "        games_howell = pg.pairwise_gameshowell(dv=self.con_col, between=self.cat_col, data=self.data)\n",
    "        return (games_howell)\n",
    "        \n",
    "    def conduct_anova_or_welch(self, p_value=0.05):\n",
    "        self.p_value = p_value\n",
    "        check_equal_variances() \n",
    "        if self.homoscedasticity_test[1] >= p_value:\n",
    "            anova_test()\n",
    "        else:\n",
    "            welch_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7f10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class handle_vif():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def compute_vif(self, considered_features: list):\n",
    "        self.considered_features = considered_features\n",
    "        X = self.data[self.considered_features]\n",
    "        X['intercept'] = 1\n",
    "        \n",
    "        self.vif = pd.DataFrame()\n",
    "        self.vif[\"Variable\"] = X.columns\n",
    "        self.vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        self.vif = self.vif[self.vif['Variable']!='intercept']#.sort_values(by='VIF', ascending=False)\n",
    "        return self.vif\n",
    "    \n",
    "    def drop_high_vif(self):\n",
    "        self.vif_table = self.vif.sort_values(by='VIF', ascending=False).reset_index(drop=True) \n",
    "    \n",
    "        while self.vif_table['VIF'].iloc[0]>5:\n",
    "            self.data.drop(self.vif_table['Variable'][0], axis=1, inplace=True)\n",
    "            computed = self.compute_vif([col for col in df.columns if col!='price']) \n",
    "            self.vif_table = computed.sort_values(by='VIF', ascending=False).reset_index(drop=True) \n",
    "\n",
    "        return self.data.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3334e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_funcs(class_name):\n",
    "  attrs = (getattr(class_name, func) for func in dir(class_name) if callable(getattr(class_name, func)))\n",
    "  methods = filter(inspect.ismethod, attrs)\n",
    "  \n",
    "  for method in methods:\n",
    "    try:\n",
    "      method()\n",
    "    except TypeError:\n",
    "      pass      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c602387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25be077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTrain(DummyTransformer):\n",
    "   \n",
    "    def __init__(self,colnames: str, targetName: str,\n",
    "                  n_fold=5, verbosity=False,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):        \n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)       \n",
    "        \n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = True)        \n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan       \n",
    "        \n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)  #Fill in the place that has become nan with the global mean\n",
    "            \n",
    "        if self.verbosity:            \n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, \n",
    "                                                                                  np.corrcoef(X[self.targetName].values,encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X.drop(self.colnames, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571bd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTest(DummyTransformer): \n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index() \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X.replace({self.encodedName: dd}, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c135528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_columns(\n",
    "    train,\n",
    "    test,\n",
    "    features,\n",
    "    target,\n",
    "    smoothing_threshold: int,\n",
    "    drop_features=False\n",
    "):\n",
    "    df_train = train.copy()\n",
    "    df_test = test.copy()\n",
    "    \n",
    "    n = len(df_train)\n",
    "    labels = sorted(list(df_train[target].unique()))\n",
    "    num_target_classes = len(labels)\n",
    "    label_avgs = []\n",
    "    for label in labels:\n",
    "        label_avgs.append(len(df_train.loc[df_train[target] == label])/n)\n",
    "    \n",
    "    df_train1 = pd.get_dummies(df_train, columns=[target])\n",
    "    targets = list(df_train1.columns[-num_target_classes:])\n",
    "    \n",
    "    for col in features:\n",
    "        print('Encoding', col, end='... ')\n",
    "        \n",
    "        unique_c = list(df_train1.groupby(by=col).mean().index)\n",
    "        counts = list(df_train1.groupby(by=col).count()[targets[0]])\n",
    "        target_means = []\n",
    "        for t in targets:\n",
    "            target_means.append(df_train1.groupby(by=col).mean()[t])\n",
    "        \n",
    "        for label in labels:\n",
    "            df_train[col+'_'+label] = 0\n",
    "            df_test[col+'_'+label] = 0\n",
    "        \n",
    "        for i, c in enumerate(unique_c):\n",
    "            class_prob = []\n",
    "            if counts[i] <= smoothing_threshold:\n",
    "                for t_i, label in enumerate(labels):\n",
    "                    class_prob.append((counts[i]-1)/10 * target_means[t_i][i] + (11-counts[i])/10 * label_avgs[t_i])\n",
    "            else:\n",
    "                for t_i, label in enumerate(labels):\n",
    "                    class_prob.append(target_means[t_i][i])\n",
    "            \n",
    "            for t_i, label in enumerate(labels):\n",
    "                df_train.loc[df_train[col]==c,col+'_'+label] = class_prob[t_i]\n",
    "            \n",
    "            if c in df_test[col].unique():\n",
    "                for l_i, label in enumerate(labels):\n",
    "                    df_test.loc[df_test[col]==c,col+'_'+label] = class_prob[l_i]\n",
    "        print('complete.')\n",
    "    \n",
    "    if drop_features:\n",
    "        df_train.drop(columns=features, inplace=True)\n",
    "        df_test.drop(columns=features, inplace=True)\n",
    "    if drop_target:\n",
    "        df_train.drop(columns=target, inplace=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e60b49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_coef(logit, x_train):\n",
    "\n",
    "    logit_coefs = pd.DataFrame(logit.coef_, columns=x_train.columns, index=['coef']).T\n",
    "    odds_change = []\n",
    "    prob_change = []\n",
    "    variance = []\n",
    "    var_importance = []\n",
    "\n",
    "    for k, v in logit_coefs.iterrows():\n",
    "\n",
    "        #changes in the odds ratio is the exp of the coefficient\n",
    "        odds_impact = np.exp(v['coef'])\n",
    "\n",
    "        probs_impact = odds_impact / (1  + odds_impact)\n",
    "\n",
    "        #variable importance multiples coef by standard deviation\n",
    "        sd = np.std(x_train[k])\n",
    "        var_imp = abs(np.exp(v['coef']*sd) - 1)\n",
    "\n",
    "        var_importance.append(var_imp)\n",
    "        variance.append(sd)\n",
    "        odds_change.append(odds_impact)\n",
    "        prob_change.append(probs_impact)\n",
    "\n",
    "    logit_coefs['SD'] = variance\n",
    "    logit_coefs['Change in Odds (%)'] = odds_change\n",
    "    logit_coefs['Change in Probability'] = prob_change\n",
    "    logit_coefs['Variable Importance'] = var_importance\n",
    "    logit_coefs = logit_coefs.reset_index().rename(columns = {'index': 'Variable'})\n",
    "    logit_coefs = logit_coefs.sort_values('Variable Importance', ascending=False)\n",
    "\n",
    "    # Plotting variable importance\n",
    "    logit_coefs = logit_coefs.sort_values('Variable Importance', ascending=False)\n",
    "    top_coefs = logit_coefs.head(10)\n",
    "    bottom_coefs = logit_coefs.tail(5)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(5, 10) ,sharex=False)\n",
    "    fig.suptitle('Variable Importance')\n",
    "    sns.barplot(ax = axes[0],\n",
    "                x = top_coefs['Variable Importance'], \n",
    "                y = top_coefs['Variable'])\n",
    "    \n",
    "     # Plotting variable importance\n",
    "    logit_coefs = logit_coefs.sort_values('Change in Odds (%)', ascending=False)\n",
    "    top_coefs2 = logit_coefs.head(10)\n",
    "    #fig.suptitle('Change in Odds for Unit Increase in X')\n",
    "    sns.barplot(ax = axes[1],\n",
    "                x = top_coefs2['Change in Odds (%)'], \n",
    "                y = top_coefs2['Variable'])\n",
    "\n",
    "    plt.show();\n",
    "    return logit_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd2ecc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data):\n",
    "    sns.set(rc={'figure.figsize':(12,9)})\n",
    "    mask = np.triu(np.ones_like(data.corr(), dtype=bool))\n",
    "    sns.heatmap(data.corr(), mask=mask, annot=True)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5ef6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_counts(data):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    data.Age.value_counts().plot(kind='bar')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53dacefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalutate_reg(y_test, pred):\n",
    "    '''Evaluation results of Linear Regression model'''\n",
    "\n",
    "    print(f'R^2: {r2_score(y_test,pred)}')\n",
    "    print(f'Root Mean Squared Error: {np.sqrt((mean_squared_error(y_test, pred)))}')\n",
    "    print(f'Mean Squared Error: {mean_squared_error(y_test, pred)}')\n",
    "    print(f'Mean Absolute Error: {mean_absolute_error(y_test,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e545e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_numeric(data, impute_method='mean'):\n",
    "    numeric_features = [column for column in data.columns if 'int' in str(data[column].dtype) or\n",
    "                        'float' in str(data[column].dtype)]\n",
    "    print(f'Null values per numeric column before: {data[numeric_features].isna().sum()}')  \n",
    "        \n",
    "    for column in numeric_features:\n",
    "        if data[column].nunique()>15:\n",
    "            if impute_method=='mean':\n",
    "                data[column].fillna(data[column].mean(), inplace=True)\n",
    "            else:\n",
    "                data[column].fillna(data[column].median(), inplace=True)\n",
    "        else:\n",
    "            continue\n",
    "    print(f'Null values per numeric column now: {data[numeric_features].isna().sum()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "662c0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian vs Real\n",
    "def plot_histogram(data, target, column, bins=100, log_scale=False):\n",
    "    anomalies = data[data.target == 1]\n",
    "    normal = df[df.target == 0]\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    fig.suptitle(f'Counts of {column} by {target}')\n",
    "    ax1.hist(anomalies[column], bins = bins, color=\"red\")\n",
    "    ax1.set_title('Anomaly')\n",
    "    ax2.hist(normal[column], bins = bins, color=\"orange\")\n",
    "    ax2.set_title('Normal')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Count')\n",
    "    if log_scale:\n",
    "        plt.yscale('log')\n",
    "    plt.xlim((np.min(df[column]), np.max(df[column])))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226aa302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imbalance(data, target):\n",
    "    f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "    data[target].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "    ax[0].set_title(target)\n",
    "    ax[0].set_ylabel('')\n",
    "    sns.countplot(target, data=data, ax=ax[1])\n",
    "    ax[1].set_title(target)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f7ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_countplot(data, column):\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    plt.figure(figsize=(9,7))\n",
    "    ax = sns.countplot(data=data, x=target, palette=\"rocket\", order=data[column].value_counts().index) \n",
    "    plt.setp(plot.get_xticklabels(), rotation=90);\n",
    "    for p in ax.patches:\n",
    "        total = len(data) \n",
    "        ax.annotate('{:.1f}%'.format(p.get_height()/total*100), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b062ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(data, features: list):\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.pairplot(data[[features]], palette = 'rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f7ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_percentage(true_price, predicted_price):\n",
    "    diff = abs(true_price - predicted_price)\n",
    "    p = (diff * 100) / true_price\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7fde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_actual(y_test, pred):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.scatter(y_test,rf_y_pred, color='green')\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb6fb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_via_cat(data, category, column, method='mean'):\n",
    "    print(f'Number of missing values before: {data[column].isna().sum()}')   \n",
    "    data[column] = data[column].fillna(data.groupby(category)[column].transform(method)) \n",
    "    print(f'Number of missing values now: {data[column].isna().sum()}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a6eb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_check_remove(data):\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    if num_duplicates > 0:\n",
    "        print(f'Number of duplicate rows before: {num_duplicates}')\n",
    "        data.drop_duplicates(inplace = True)\n",
    "        print(f'Number of duplicate rows now: {data.duplicated().sum()}')\n",
    "    else:\n",
    "        print('There are no duplicate rows in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a511f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder_smoother(data, smooth_val: int):\n",
    "    for col in data.columns: \n",
    "        t = TargetEncoder(smoothing=smooth_val)\n",
    "        data[col] = t.fit_transform(data[col], target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "923611d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_stripper(data):\n",
    "    for f in data.columns:\n",
    "        if data[f].dtype == 'O':\n",
    "            data[f] = data[f].str.strip()\n",
    "    print('Categorical features\\' values are stripped')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8df6c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_colnames(data):\n",
    "    data.rename(columns=lambda x: x.lower().replace(' ', '_').replace('-', '_').replace(',', ''), inplace=True)\n",
    "    return print(f'Column names cleaned: {data.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8116ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_cols(data, null_ratio_threshold):\n",
    "    total_dropped = 0\n",
    "    dropped_columns = []\n",
    "    for f in data.columns:\n",
    "        number_of_missing = data[f].isna().sum()\n",
    "        ratio = number_of_missing / data.shape[0]\n",
    "        if ratio>null_ratio_threshold/100:\n",
    "            total_dropped =+ 1 \n",
    "            dropped_columns.append(f)\n",
    "            data.drop(f, axis=1, inplace=True)\n",
    "        else:\n",
    "            continue\n",
    "    if total_dropped!=0:\n",
    "        print(f'Dropped columns are: {dropped_columns}') \n",
    "    else:\n",
    "        print('No column is dropped') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cf0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(file_name: str):\n",
    "    r_raw = dt.fread(file_name)\n",
    "    data = r_raw.to_pandas() \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5adf1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_categorical(data):\n",
    "    for column in data.columns:\n",
    "        if 'object' in str(data[column].dtype):\n",
    "            vals = []\n",
    "            for value in data[column].values:\n",
    "                if value=='nan':\n",
    "                    vals.append(value)\n",
    "                else:\n",
    "                    vals.append(value.lower())\n",
    "            data[column] = pd.Series(vals).to_frame()     \n",
    "    print('Values lowercased: ')\n",
    "    return data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92234e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(data, pct_threshold=0.4): \n",
    "    \n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage before: {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if 'int' in str(col_type): \n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "        \n",
    "        elif col_type=='object':\n",
    "            if data[col].nunique() / data[col].shape[0] < pct_threshold:  \n",
    "                data[col] = data[col].astype('category') \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage now : {:.2f} MB'.format(end_mem))\n",
    "    print('Memory usage decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a0d1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_one_boxplt(data):\n",
    "    num_cols = data.select_dtypes(include=['int','int64','float'])\n",
    "    melted_df = pd.melt(num_cols)\n",
    "    sns.set(rc={'figure.figsize':(6,4)})\n",
    "    sns.boxplot(x='value',y='variable', data=melted_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2831db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_multi_boxplt(data):\n",
    "    for i in data.columns:\n",
    "        sns.set(rc={'figure.figsize':(6,4)})\n",
    "        temp_df = data.loc[:,i]\n",
    "        sns.boxplot(temp_df)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f8c251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_missing(data):\n",
    "  sns.set(rc={'figure.figsize':(10,7)})\n",
    "  sns.heatmap(data.isna(), yticklabels = False, cbar = False, cmap = plt.cm.magma)\n",
    "  plt.title(label = 'Heatmap for Missing Values', fontsize = 16, color='red')\n",
    "  plt.xlabel(xlabel = 'Features', fontsize = 16, color='red')\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93a2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortValues(nums: list, ascending=False):\n",
    "    '''\n",
    "    Sort values in descending order\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ordered = []\n",
    "    for _ in range(len(nums)):\n",
    "        maxi = nums[0]\n",
    "        for num in nums:\n",
    "            if num>maxi:\n",
    "                maxi=num\n",
    "        nums.remove(maxi)\n",
    "        ordered.append(maxi)\n",
    "    return ordered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7512c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(x_train, y_train, x_test, y_test, preds, mdl):\n",
    "    \n",
    "    train_acc = mdl.score(x_train,y_train)\n",
    "    test_acc = mdl.score(x_test, y_test)\n",
    "    rmse = (np.sqrt(mean_squared_error(y_test, preds)))\n",
    "    \n",
    "    results = {'Train_acc': train_acc, 'Test_acc': test_acc, 'rmse': rmse}\n",
    "    model = 'Value'\n",
    "    model_metrics = pd.DataFrame(results.items(), columns = ['Metric', str(model)]).set_index('Metric')\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00fb77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(x_train, y_train, x_test, y_test, preds ,probs ,mdl): #Evaluation Metrics\n",
    "    Accuracy = accuracy_score(y_test, preds)\n",
    "    Precision  = precision_score(y_test, preds)\n",
    "    Recall = recall_score(y_test, preds)\n",
    "\n",
    "    #Confusion Matrix\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, preds, labels=[0,1]))\n",
    "    TN = cm[0][0]                                                                                       \n",
    "    FN = cm[0][1]                                                                                          \n",
    "    FP = cm[1][0]                                                                                       \n",
    "    TP = cm[1][1]\n",
    "    TPR = TN/(FP+TN)   \n",
    "    FPR = FP/(FP+TN)\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr )\n",
    "\n",
    "    logit_summary = {'Accuracy': Accuracy, \n",
    "                     'Precision': Precision, \n",
    "                     'Recall': Recall, \n",
    "                     'True Positive Rate': TPR, \n",
    "                     'False Positive Rate': FPR,\n",
    "                    }\n",
    "    \n",
    "    model = 'Value'\n",
    "    class_metrics = pd.DataFrame(logit_summary.items(), columns = ['Metric', str(model)]).set_index('Metric')\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    plot_confusion_matrix(mdl, x_test, y_test, cmap=plt.cm.Blues, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix', y = 1.1)\n",
    "    \n",
    "    return class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a111a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class compute_outliers():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def coerce_outliers_iqr(self, value):\n",
    "        self.value = value\n",
    "        if self.value > upperlimit:\n",
    "            self.value = upperlimit\n",
    "        elif self.value < lowerlimit:\n",
    "            self.value = lowerlimit\n",
    "        return self.value    \n",
    "        \n",
    "    def apply_iqr(self, const=1.5):\n",
    "        for feature in self.data.columns[:-1]: \n",
    "            Q3 = self.data[feature].quantile(q = 0.75)\n",
    "            Q1 = self.data[feature].quantile(q = 0.25)\n",
    "            IQR = Q3 - Q1  \n",
    "            outlier_range = IQR * const\n",
    "            upperlimit = Q3 + outlier_range\n",
    "            lowerlimit = Q1 - outlier_range\n",
    "            self.data[feature] = self.data[feature].apply(self.coerce_outliers_iqr)\n",
    "            outlier_vals = self.find_outliers_iqr()\n",
    "            return outlier_vals\n",
    "    \n",
    "    def find_outlier_records_zscore(self, column_name: str, no_std=3):\n",
    "        no_outliers = 0 \n",
    "        values = data[column_name].unique() \n",
    "        upper_border = np.asarray(self.data[column_name]).mean() + no_std*(np.asarray(self.data[column_name]).std())\n",
    "        lower_border = np.asarray(self.data[column_name]).mean() - no_std*(np.asarray(self.data[column_name]).std()) \n",
    "        for value in values:\n",
    "            if value>upper_border:\n",
    "                no_outliers+=int(self.data[column_name].value_counts()[value])\n",
    "            elif value<lower_border:\n",
    "                no_outliers+=int(self.data[column_name].value_counts()[value])\n",
    "            else:\n",
    "                continue\n",
    "        print(f'''Number of outlier records in {column_name} column: {no_outliers}''')   \n",
    "        \n",
    "    def coerce_outliers_zscore(column_name: str, no_std=3):\n",
    "        values = data[column_name].unique() \n",
    "        upper_border = np.asarray(self.data[column_name]).mean() + no_std*(np.asarray(self.data[column_name]).std())\n",
    "        lower_border = np.asarray(self.data[column_name]).mean() - no_std*(np.asarray(self.data[column_name]).std()) \n",
    "        no_of_outliers_before = 0\n",
    "        for value in values:\n",
    "            if value>upper_border:\n",
    "                no_of_outliers_before =+ 1 \n",
    "                self.data[column_name].astype(float).replace({value: upper_border}, inplace=True) \n",
    "            elif value<lower_border:\n",
    "                no_of_outliers_before =+ 1      \n",
    "                self.data[column_name].astype(float).replace({value: lower_border}, inplace=True)   \n",
    "            \n",
    "    def find_outliers_iqr(outlier_range_val=1.5):\n",
    "        for column in self.data.select_dtypes(include='number').columns:\n",
    "            Q3 = self.data[column].quantile(q = 0.75)\n",
    "            Q1 = self.data[column].quantile(q = 0.25)\n",
    "            IQR = Q3 - Q1\n",
    "            outlier_range = IQR * outlier_range_val\n",
    "            upperlimit = Q3 + outlier_range\n",
    "            lowerlimit = Q1 - outlier_range\n",
    "            no_outliers = self.data.loc[(self.data[column]>upperlimit) | (self.data[column]<lowerlimit)].shape[0]\n",
    "        print(f'''Number of outlier records in {column} column: {no_outliers}''')               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ff2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rf_feat_importance(rf_model, top_n_feats=10):\n",
    "    rf_features_importance=pd.DataFrame({\n",
    "    \"Features\":list(rf_model.feature_importances_)\n",
    "    },index=X.columns).sort_values(by=\"Features\", axis=0, ascending=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.barh(rf_features_importance.index[-top_n_feats:],rf_features_importance.Features[-top_n_feats:],color=\"purple\")\n",
    "    for i, v in enumerate(rf_features_importance.Features[-top_n_feats:]):\n",
    "        ax.text(v+0.001, i,('% 0.2f' % v)+\"%\")\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5543962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "def plot_summary(model, X_train):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap.summary_plot(shap_values[1], X_train.astype(\"float\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
